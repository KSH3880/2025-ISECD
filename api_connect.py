import pandas as pd
from concurrent.futures import ThreadPoolExecutor, as_completed
import requests
import time
import random
from collections import defaultdict



# ì „ì—­ ë¸”ë™ë¦¬ìŠ¤íŠ¸ì™€ ë¸”ë½ íƒ€ì´ë¨¸
blacklisted_keys = set()
blacklist_timers = defaultdict(float)  # key_idx: timestamp when it can be retried

# ê¸°ë³¸ íŒŒë¼ë¯¸í„°
API_RETRY_COOLDOWN = 120  # 429 ê±¸ë¦¬ë©´ 2ë¶„ê°„ ë¸”ë™
MIN_SLEEP = 0.05
MAX_SLEEP = 0.3

def get_route_info_with_rotation(origin, destination, api_keys, key_index, u, v):
    attempts = 0
    total_keys = len(api_keys)

    while attempts < total_keys:
        key_idx = (key_index + attempts) % total_keys

        # ë¸”ë™ë¦¬ìŠ¤íŠ¸ íƒ€ì´ë¨¸ í™•ì¸
        if key_idx in blacklisted_keys:
            now = time.time()
            if now < blacklist_timers[key_idx]:
                attempts += 1
                continue
            else:
                blacklisted_keys.remove(key_idx)

        api_key = api_keys[key_idx]
        url = "https://apis-navi.kakaomobility.com/v1/directions"
        headers = {"Authorization": f"KakaoAK {api_key}"}
        params = {
            "origin": f"{origin[0]},{origin[1]},angle=270",
            "destination": f"{destination[0]},{destination[1]}",
            "summary": "true",
            "priority": "RECOMMEND",
            "car_fuel": "GASOLINE",
            "car_hipass": "false",
            "alternatives": "false",
            "road_details": "false"
        }

        try:
            response = requests.get(url, headers=headers, params=params, timeout=10)
            if response.status_code == 200:
                data = response.json()
                if 'routes' in data and data['routes'] and 'sections' in data['routes'][0]:
                    section = data['routes'][0]['sections'][0]
                    duration = section['duration']
                    print(f"[âœ… Success] {origin} â†’ {destination} | {duration:.1f} sec | API-{key_idx+1}")
                    return {
                        'u': u, 'v': v,
                        'u_x': origin[0], 'u_y': origin[1],
                        'v_x': destination[0], 'v_y': destination[1],
                        'duration': duration
                    }
                else:
                    print(f"[âš ï¸ No sections] {origin} â†’ {destination} | API-{key_idx+1}")
            else:
                print(f"[âŒ HTTP {response.status_code}] {origin} â†’ {destination} | API-{key_idx+1}")
                if response.status_code == 429:
                    print(f"[ğŸš« Rate Limited] API-{key_idx+1} temporarily blacklisted.")
                    blacklisted_keys.add(key_idx)
                    blacklist_timers[key_idx] = time.time() + API_RETRY_COOLDOWN
        except Exception as e:
            print(f"[â— Exception] {origin} â†’ {destination} | API-{key_idx+1} | {e}")

        attempts += 1
        time.sleep(random.uniform(MIN_SLEEP, MAX_SLEEP))  # âœ… Rate ë¶„ì‚°ì„ ìœ„í•´ sleep ëœë¤ ì„¤ì •

    print(f"[âŒ All APIs failed] {origin} â†’ {destination}")
    return None

def process_edges_parallel_with_keys(edges_df, api_keys, max_workers=5):
    results = []
    failures = []

    def task(row_index_row):
        idx, row = row_index_row
        origin = (row['u_x'], row['u_y'])
        destination = (row['v_x'], row['v_y'])
        result = get_route_info_with_rotation(origin, destination, api_keys, idx, row['u'], row['v'])
        return result if result else row  # ì‹¤íŒ¨í•œ ê²½ìš° row ìì²´ ë°˜í™˜

    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        indexed_rows = list(edges_df.iterrows())
        futures = [executor.submit(task, pair) for pair in indexed_rows]

        for future in as_completed(futures):
            try:
                result = future.result()
                if isinstance(result, dict):
                    results.append(result)
                else:
                    failures.append(result)
            except Exception as e:
                print(f"[â— Future Exception] {e}")

    return pd.DataFrame(results), pd.DataFrame(failures)


#####csvì…ë ¥
import pandas as pd
filtered_edges = pd.read_csv("filtered_edges.csv")

#####apií‚¤ ì…ë ¥ 
api_keys = [
]
#####

# ğŸ” 1ì°¨ ë³‘ë ¬ ì‹¤í–‰
success_df, fail_df = process_edges_parallel_with_keys(filtered_edges, api_keys, max_workers=10)

# ğŸ”„ ì‹¤íŒ¨í•œ ìš”ì²­ ì¬ì‹œë„ (ë‹¤ì‹œ ë³‘ë ¬ ì²˜ë¦¬)
retry_df, _ = process_edges_parallel_with_keys(fail_df, api_keys, max_workers=10)

# ğŸ“¦ ìµœì¢… ê²°ê³¼ í•©ì¹˜ê¸°
assigned_edges = pd.concat([success_df, retry_df], ignore_index=True)
print(f"âœ… ìµœì¢… ì„±ê³µ: {len(assigned_edges)} / {len(filtered_edges)}")

